GPU available: False, used: False
TPU available: False, using: 0 TPU cores

  | Name             | Type                | Params
---------------------------------------------------------
0 | anchor_generator | AnchorGenerator     | 0     
1 | backbone         | BackboneWithFPN     | 14.3 M
2 | cosloss          | CosineEmbeddingLoss | 0     
3 | model            | RetinaNet           | 23.2 M
4 | bbone            | ResNet              | 11.7 M
5 | extractor        | Sequential          | 11.2 M
6 | teacher_model    | RecognitionModel    | 11.3 M
7 | tm               | Sequential          | 11.2 M
---------------------------------------------------------
46.2 M    Trainable params
0         Non-trainable params
46.2 M    Total params
184.650   Total estimated model params size (MB)
/Users/emilecarron/opt/anaconda3/envs/thesis/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  warnings.warn(*args, **kwargs)
Validation sanity check: 0it [00:00, ?it/s]Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]Validation sanity check:  50%|█████     | 1/2 [00:10<00:10, 10.57s/it]Validation sanity check: 100%|██████████| 2/2 [00:20<00:00, 10.51s/it]/Users/emilecarron/opt/anaconda3/envs/thesis/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  warnings.warn(*args, **kwargs)
                                                                      Training: 0it [00:00, ?it/s]Training:   0%|          | 0/534 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/534 [00:00<?, ?it/s] > /Users/emilecarron/projects/thesis/detectie/retinanet.py(144)training_step()
-> x, y = batch
(Pdb) > /Users/emilecarron/projects/thesis/detectie/retinanet.py(145)training_step()
-> y = [{'boxes': b, 'labels': l, 'embedding': e}
(Pdb) > /Users/emilecarron/projects/thesis/detectie/retinanet.py(146)training_step()
-> for b, l, e in zip(y['boxes'],y['labels'], y['embedding'])
(Pdb) > /Users/emilecarron/projects/thesis/detectie/retinanet.py(149)training_step()
-> boxes = y[0]['boxes'].int()
(Pdb) > /Users/emilecarron/projects/thesis/detectie/retinanet.py(150)training_step()
-> counter = 0
(Pdb) > /Users/emilecarron/projects/thesis/detectie/retinanet.py(151)training_step()
-> for idx in boxes:
(Pdb) > /Users/emilecarron/projects/thesis/detectie/retinanet.py(152)training_step()
-> height = idx[3]-idx[1]
(Pdb) tensor([[  91,  138,  191,  211],
        [ 529,  501,  578,  574],
        [ 471,  537,  529,  562],
        [ 430,  539,  467,  584],
        [ 401,  526,  432,  562],
        [ 351,  528,  387,  565],
        [ 310,  539,  344,  577],
        [ 260,  553,  290,  570],
        [ 221,  529,  257,  563],
        [ 184,  536,  219,  577],
        [ 151,  534,  185,  576],
        [ 131,  530,  152,  576],
        [  93,  529,  134,  572],
        [  60,  532,   94,  570],
        [   6,  511,   56,  570],
        [   0,  440,   11,  492],
        [ 473,  452,  515,  502],
        [ 433,  433,  475,  480],
        [ 504,   15,  575,   82],
        [ 472,   36,  505,   80],
        [ 431,   47,  475,   79],
        [ 378,   33,  429,   76],
        [ 297,   14,  348,   78],
        [ 240,   14,  302,   76],
        [ 574,  465,  635,  576],
        [ 167,    5,  224,   72],
        [  61,    3,  120,   69],
        [  14,    4,   65,   68],
        [ 143,  429,  204,  485],
        [ 288,  429,  340,  471],
        [ 335,  452,  382,  502],
        [ 383,  446,  427,  493],
        [ 114,    4,  173,   71],
        [ 628,  465,  691,  572],
        [ 684,  490,  734,  585],
        [ 727,  529,  806,  584],
        [ 406,  635,  489,  731],
        [ 493,  593,  552,  669],
        [ 542,  641,  619,  735],
        [ 611,  625,  678,  736],
        [ 676,  606,  741,  697],
        [ 736,  612,  814,  719],
        [ 353,  622,  414,  726],
        [ 806,  612,  884,  722],
        [ 953,  680, 1026,  744],
        [ 934,  604, 1002,  646],
        [1025,  659, 1076,  702],
        [1111,  682, 1182,  737],
        [1138,  606, 1192,  666],
        [ 192,  140,  306,  216],
        [ 881,  630,  929,  700],
        [ 571,   16,  644,   88],
        [ 308,  620,  358,  727],
        [ 191,  606,  252,  701],
        [ 817,  471,  883,  527],
        [ 809,  527,  874,  584],
        [ 872,  532,  935,  587],
        [ 932,  525, 1001,  589],
        [1002,  515, 1052,  591],
        [1046,  481, 1132,  593],
        [ 256,  621,  315,  726],
        [1124,  476, 1192,  581],
        [1187,  525, 1238,  570],
        [   0,  626,   41,  719],
        [  34,  653,   87,  727],
        [  92,  640,  129,  704],
        [ 122,  629,  184,  727],
        [1191,  486, 1244,  526],
        [ 637,   19,  717,   90],
        [1215,  612, 1301,  726],
        [ 781,   24,  848,   92],
        [ 276,  236,  306,  296],
        [ 195,  239,  266,  306],
        [ 119,  236,  194,  303],
        [  49,  235,  119,  307],
        [   0,  234,   54,  306],
        [1272,   58, 1328,  110],
        [1292,  183, 1333,  210],
        [1259,  153, 1294,  207],
        [1224,  142, 1265,  206],
        [1146,  141, 1229,  205],
        [1086,  144, 1151,  203],
        [1010,  148, 1045,  193],
        [ 964,  141, 1012,  202],
        [ 302,  244,  371,  311],
        [   6,  447,   61,  496],
        [   6,  135,   97,  208],
        [1209,   55, 1273,  106],
        [1069,   55, 1149,  104],
        [1042,   63, 1071,  101],
        [ 898,  127,  945,  191],
        [ 858,  126,  903,  193],
        [ 809,  125,  857,  191],
        [ 767,  123,  809,  193],
        [ 709,  139,  767,  193],
        [ 669,  118,  707,  185],
        [ 621,  123,  669,  184],
        [ 569,  116,  615,  184],
        [ 523,  110,  573,  182],
        [  90,  428,  143,  470],
        [ 375,  284,  430,  314],
        [ 513,  202,  617,  299],
        [ 613,  227,  706,  302],
        [1284,  372, 1321,  452],
        [1206,  368, 1263,  454],
        [1136,  370, 1205,  450],
        [1040,  348, 1078,  450],
        [ 992,  341, 1049,  450],
        [ 903,  329,  983,  429],
        [ 831,  327,  906,  430],
        [ 776,  342,  835,  440],
        [ 695,  349,  775,  443],
        [ 634,  357,  701,  441],
        [ 577,  354,  633,  441],
        [ 527,  325,  584,  413],
        [ 443,  348,  516,  418],
        [ 361,  345,  449,  416],
        [ 333,  345,  368,  414],
        [ 297,  341,  339,  413],
        [ 208,  339,  296,  412],
        [ 113,  336,  199,  410],
        [  68,  326,  116,  388],
        [   0,  334,   10,  414],
        [1269,  268, 1319,  313],
        [1187,  241, 1270,  310],
        [1095,  211, 1179,  240],
        [1103,  241, 1163,  310],
        [1037,  253, 1107,  313],
        [ 946,  248, 1036,  310],
        [ 872,  215,  921,  303],
        [ 788,  230,  858,  296],
        [ 703,  228,  792,  304],
        [ 379,  149,  454,  217],
        [ 712,   20,  782,   91],
        [1152,   54, 1213,  105],
        [ 994,   51, 1048,  101],
        [ 846,   45,  901,   93],
        [ 897,   45,  958,   95],
        [ 954,   50,  998,   99],
        [ 301,  149,  384,  218]], dtype=torch.int32)
(Pdb) > /Users/emilecarron/projects/thesis/detectie/retinanet.py(153)training_step()
-> width = idx[2]-idx[0]
(Pdb) > /Users/emilecarron/projects/thesis/detectie/retinanet.py(154)training_step()
-> if height < 7:
(Pdb) > /Users/emilecarron/projects/thesis/detectie/retinanet.py(157)training_step()
-> if width < 7:
(Pdb) > /Users/emilecarron/projects/thesis/detectie/retinanet.py(161)training_step()
-> image = torchvision.transforms.functional.crop(x, idx[1], idx[0], height, width)
(Pdb) > /Users/emilecarron/projects/thesis/detectie/retinanet.py(162)training_step()
-> self.tm.eval()
(Pdb) > /Users/emilecarron/projects/thesis/detectie/retinanet.py(163)training_step()
-> predictions = self.tm(image)
(Pdb) > /Users/emilecarron/projects/thesis/detectie/retinanet.py(164)training_step()
-> embedding_path = self.data_dir + '/SKU110K/annotations/embeddings/embedding' + str(train_idx) + '_' + str(idx)
(Pdb) AttributeError: 'RetinaNetLightning' object has no attribute 'data_dir'
> /Users/emilecarron/projects/thesis/detectie/retinanet.py(164)training_step()
-> embedding_path = self.data_dir + '/SKU110K/annotations/embeddings/embedding' + str(train_idx) + '_' + str(idx)
(Pdb) Epoch 0:   0%|          | 0/534 [00:51<?, ?it/s]
Traceback (most recent call last):
  File "train.py", line 78, in <module>
    main(args)
  File "train.py", line 59, in main
    trainer.fit(model, dm)
  File "/Users/emilecarron/opt/anaconda3/envs/thesis/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py", line 499, in fit
    self.dispatch()
  File "/Users/emilecarron/opt/anaconda3/envs/thesis/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py", line 546, in dispatch
    self.accelerator.start_training(self)
  File "/Users/emilecarron/opt/anaconda3/envs/thesis/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py", line 73, in start_training
    self.training_type_plugin.start_training(trainer)
  File "/Users/emilecarron/opt/anaconda3/envs/thesis/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py", line 114, in start_training
    self._results = trainer.run_train()
  File "/Users/emilecarron/opt/anaconda3/envs/thesis/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py", line 637, in run_train
    self.train_loop.run_training_epoch()
  File "/Users/emilecarron/opt/anaconda3/envs/thesis/lib/python3.6/site-packages/pytorch_lightning/trainer/training_loop.py", line 492, in run_training_epoch
    batch_output = self.run_training_batch(batch, batch_idx, dataloader_idx)
  File "/Users/emilecarron/opt/anaconda3/envs/thesis/lib/python3.6/site-packages/pytorch_lightning/trainer/training_loop.py", line 654, in run_training_batch
    self.optimizer_step(optimizer, opt_idx, batch_idx, train_step_and_backward_closure)
  File "/Users/emilecarron/opt/anaconda3/envs/thesis/lib/python3.6/site-packages/pytorch_lightning/trainer/training_loop.py", line 433, in optimizer_step
    using_lbfgs=is_lbfgs,
  File "/Users/emilecarron/opt/anaconda3/envs/thesis/lib/python3.6/site-packages/pytorch_lightning/core/lightning.py", line 1390, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/Users/emilecarron/opt/anaconda3/envs/thesis/lib/python3.6/site-packages/pytorch_lightning/core/optimizer.py", line 214, in step
    self.__optimizer_step(*args, closure=closure, profiler_name=profiler_name, **kwargs)
  File "/Users/emilecarron/opt/anaconda3/envs/thesis/lib/python3.6/site-packages/pytorch_lightning/core/optimizer.py", line 134, in __optimizer_step
    trainer.accelerator.optimizer_step(optimizer, self._optimizer_idx, lambda_closure=closure, **kwargs)
  File "/Users/emilecarron/opt/anaconda3/envs/thesis/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py", line 277, in optimizer_step
    self.run_optimizer_step(optimizer, opt_idx, lambda_closure, **kwargs)
  File "/Users/emilecarron/opt/anaconda3/envs/thesis/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py", line 282, in run_optimizer_step
    self.training_type_plugin.optimizer_step(optimizer, lambda_closure=lambda_closure, **kwargs)
  File "/Users/emilecarron/opt/anaconda3/envs/thesis/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py", line 163, in optimizer_step
    optimizer.step(closure=lambda_closure, **kwargs)
  File "/Users/emilecarron/opt/anaconda3/envs/thesis/lib/python3.6/site-packages/torch/optim/optimizer.py", line 89, in wrapper
    return func(*args, **kwargs)
  File "/Users/emilecarron/opt/anaconda3/envs/thesis/lib/python3.6/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/Users/emilecarron/opt/anaconda3/envs/thesis/lib/python3.6/site-packages/torch/optim/adam.py", line 66, in step
    loss = closure()
  File "/Users/emilecarron/opt/anaconda3/envs/thesis/lib/python3.6/site-packages/pytorch_lightning/trainer/training_loop.py", line 649, in train_step_and_backward_closure
    split_batch, batch_idx, opt_idx, optimizer, self.trainer.hiddens
  File "/Users/emilecarron/opt/anaconda3/envs/thesis/lib/python3.6/site-packages/pytorch_lightning/trainer/training_loop.py", line 742, in training_step_and_backward
    result = self.training_step(split_batch, batch_idx, opt_idx, hiddens)
  File "/Users/emilecarron/opt/anaconda3/envs/thesis/lib/python3.6/site-packages/pytorch_lightning/trainer/training_loop.py", line 293, in training_step
    training_step_output = self.trainer.accelerator.training_step(args)
  File "/Users/emilecarron/opt/anaconda3/envs/thesis/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py", line 156, in training_step
    return self.training_type_plugin.training_step(*args)
  File "/Users/emilecarron/opt/anaconda3/envs/thesis/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py", line 125, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
  File "/Users/emilecarron/projects/thesis/detectie/retinanet.py", line 164, in training_step
    predictions = self.tm(image)
  File "/Users/emilecarron/opt/anaconda3/envs/thesis/lib/python3.6/bdb.py", line 57, in trace_dispatch
    return self.dispatch_exception(frame, arg)
  File "/Users/emilecarron/opt/anaconda3/envs/thesis/lib/python3.6/bdb.py", line 113, in dispatch_exception
    if self.quitting: raise BdbQuit
bdb.BdbQuit
