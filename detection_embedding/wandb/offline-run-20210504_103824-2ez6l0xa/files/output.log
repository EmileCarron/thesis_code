GPU available: False, used: False
TPU available: False, using: 0 TPU cores

  | Name             | Type                | Params
---------------------------------------------------------
0 | anchor_generator | AnchorGenerator     | 0     
1 | backbone         | BackboneWithFPN     | 14.3 M
2 | cosloss          | CosineEmbeddingLoss | 0     
3 | model            | RetinaNet           | 23.2 M
4 | bbone            | ResNet              | 11.7 M
5 | extractor        | Sequential          | 11.2 M
6 | teacher_model    | RecognitionModel    | 11.3 M
7 | tm               | Sequential          | 11.2 M
---------------------------------------------------------
46.2 M    Trainable params
0         Non-trainable params
46.2 M    Total params
184.650   Total estimated model params size (MB)
/Users/emilecarron/opt/anaconda3/envs/thesis/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  warnings.warn(*args, **kwargs)
Validation sanity check: 0it [00:00, ?it/s]Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]Validation sanity check:  50%|█████     | 1/2 [00:10<00:10, 10.03s/it]Validation sanity check: 100%|██████████| 2/2 [00:20<00:00, 10.06s/it]/Users/emilecarron/opt/anaconda3/envs/thesis/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  warnings.warn(*args, **kwargs)
                                                                      Training: 0it [00:00, ?it/s]Training:   0%|          | 0/534 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/534 [00:00<?, ?it/s] > /Users/emilecarron/projects/thesis/detectie/retinanet.py(145)training_step()
-> x, y = batch
(Pdb) > /Users/emilecarron/projects/thesis/detectie/retinanet.py(146)training_step()
-> y = [{'boxes': b, 'labels': l, 'embedding': e}
(Pdb) > /Users/emilecarron/projects/thesis/detectie/retinanet.py(147)training_step()
-> for b, l, e in zip(y['boxes'],y['labels'], y['embedding'])
(Pdb) > /Users/emilecarron/projects/thesis/detectie/retinanet.py(150)training_step()
-> boxes = y[0]['boxes'].int()
(Pdb) > /Users/emilecarron/projects/thesis/detectie/retinanet.py(151)training_step()
-> counter = 0
(Pdb) > /Users/emilecarron/projects/thesis/detectie/retinanet.py(152)training_step()
-> for idx in boxes:
(Pdb) > /Users/emilecarron/projects/thesis/detectie/retinanet.py(153)training_step()
-> height = idx[3]-idx[1]
(Pdb) > /Users/emilecarron/projects/thesis/detectie/retinanet.py(154)training_step()
-> width = idx[2]-idx[0]
(Pdb) > /Users/emilecarron/projects/thesis/detectie/retinanet.py(155)training_step()
-> if height < 7:
(Pdb) > /Users/emilecarron/projects/thesis/detectie/retinanet.py(158)training_step()
-> if width < 7:
(Pdb) > /Users/emilecarron/projects/thesis/detectie/retinanet.py(162)training_step()
-> image = torchvision.transforms.functional.crop(x, idx[1], idx[0], height, width)
(Pdb) > /Users/emilecarron/projects/thesis/detectie/retinanet.py(163)training_step()
-> self.tm.eval()
(Pdb) > /Users/emilecarron/projects/thesis/detectie/retinanet.py(164)training_step()
-> predictions = self.tm(image)
(Pdb) > /Users/emilecarron/projects/thesis/detectie/retinanet.py(165)training_step()
-> embedding_path = self.data_dir + '/SKU110K/annotations/embeddings/embedding' + str(batch_idx) + '_' + str(counter)+'.pt'
(Pdb) > /Users/emilecarron/projects/thesis/detectie/retinanet.py(166)training_step()
-> torch.save(predictions, embedding_path)
(Pdb) tensor([[[[0.1804, 0.1686, 0.1569,  ..., 0.9255, 0.9412, 0.9961],
          [0.1569, 0.1647, 0.1647,  ..., 0.9922, 0.8549, 0.8627],
          [0.1490, 0.1490, 0.1529,  ..., 0.8941, 0.8784, 0.4824],
          ...,
          [0.9569, 0.7804, 0.6588,  ..., 0.4824, 0.1333, 0.0667],
          [0.8667, 0.9725, 0.8039,  ..., 0.0745, 0.0863, 0.0784],
          [0.9765, 1.0000, 0.9961,  ..., 0.0941, 0.1098, 0.1020]],

         [[0.1569, 0.1451, 0.1333,  ..., 0.9098, 0.9137, 0.9725],
          [0.1333, 0.1373, 0.1412,  ..., 0.9804, 0.8431, 0.8549],
          [0.1255, 0.1255, 0.1294,  ..., 0.9059, 0.9216, 0.5843],
          ...,
          [0.9490, 0.7529, 0.6078,  ..., 0.4275, 0.0824, 0.0157],
          [0.8667, 0.9647, 0.7804,  ..., 0.0314, 0.0471, 0.0431],
          [0.9765, 1.0000, 0.9922,  ..., 0.0588, 0.0745, 0.0667]],

         [[0.2510, 0.2392, 0.2275,  ..., 0.9882, 0.9843, 1.0000],
          [0.2275, 0.2353, 0.2353,  ..., 1.0000, 0.9216, 0.9255],
          [0.2196, 0.2196, 0.2235,  ..., 0.9686, 0.9686, 0.6588],
          ...,
          [0.9843, 0.8549, 0.7451,  ..., 0.4863, 0.1373, 0.0706],
          [0.9216, 0.9961, 0.8667,  ..., 0.0863, 0.1020, 0.0980],
          [1.0000, 1.0000, 1.0000,  ..., 0.1137, 0.1294, 0.1216]]]])
(Pdb) 